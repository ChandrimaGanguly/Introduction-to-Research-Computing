{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good practice for coding\n",
    "\n",
    "Once you have written some initial code from your prototype with good documentation and a nice modular structure (and of course carefully tracked by git) there are two things you will want to do as you develop the code further\n",
    "\n",
    "- Debug\n",
    "- Optimise\n",
    "\n",
    "For the first Python has a good inbuilt debugger that will help you, `pdg`\n",
    "\n",
    "## Debugging\n",
    "If you run code that has raised an exception in jupyter or ipython you can use the magic command `%debug` to launch an interactive debugger where you can examine the code line by line.  Here are the most useful commands\n",
    "\n",
    "| Command | Desciption |\n",
    "|---|---|\n",
    "| u | Up |\n",
    "| d | Down|\n",
    "| p | Print |\n",
    "| q | Quit |\n",
    "\n",
    "This is best seen in an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottom_func(x):\n",
    "    y = x**2\n",
    "    return str(x) + \" squared equals \" + str(y)\n",
    "\n",
    "def top_func(z):\n",
    "    result = bottom_func(z)\n",
    "    return result\n",
    "        \n",
    "top_func('7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be turned on automatically with `%pdb on` so whenever an exception is raised the debugger is launched automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run the code interactivly line by line using `%run -d` which can be more useful if your code is just wrong rather than breaking.  If you launch code with this then you can step through it with the following commands:\n",
    "\n",
    "| Command | Desciption |\n",
    "|---|---|\n",
    "| n | Next line |\n",
    "| s | Step into function|\n",
    "| c | Continue to run normally |\n",
    "| q | Quit |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -d Code/simple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run the debugger from the command line with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ">> python3 -m pdb myscript.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit testing\n",
    "\n",
    "The best way to debug your code is to catch them before they happen which you can do with unit testing.  The ideas is that you would set up a bunch of tests for the code then everytime you do a commit to master or after doing major edits you run them to check you haven't broken anything.  For the code calculating the integral in the previous notebook you may want to to create tests that check you polynomials are OK (by checking orthonormality) or that the final integral with Gauss-Legendre quadriture is correct for large l (ie set X = $\\delta_{l,200}$ and see if you get the correct answer, 0.000018285996687338485).  \n",
    "\n",
    "Having set up these tests you can then automate them to create a test package that runs, say, before a push to a central repository.  This is standard practise in commercial development enviroments and if you can include them in interview test questions this will put you above the majority of applicants.\n",
    "\n",
    "It's a good idea to get into the habit of adding them for functions, ideally before you write it.  Then you can use them to check your code does what you thought it should. Luckly in python basic ones are easy to do, you can just add it to the docstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest\n",
    "\n",
    "def function(x):\n",
    "    \"\"\"\n",
    "    Calculate x + 2\n",
    "    >>> function(5)\n",
    "    7\n",
    "    \"\"\"\n",
    "    return x+3\n",
    "\n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fine for super simple tests but isn't much use once you write functions that process data rather than just a number.  There are alot of packages available but `pytest` is the standard.  This runs from the terminal and looks for any functions with the name `test_somefunction` or `somefunction_test` then run them.  These functions should contain some code to run then tests to apply to the outputs using the command `assert` which accepts any booleian argument.  If our function was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addtwo(x):\n",
    "    \"\"\"\n",
    "        Add 2 to x\n",
    "    \"\"\"\n",
    "    return x+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then our test could look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_addtwo():\n",
    "    \"\"\"\n",
    "        Test addtwo\n",
    "    \"\"\"\n",
    "    assert( addtwo(3)==5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are in the files simple.py in the directory `Code`. We can test them from the command line using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pytest Code/simple.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tests can also be held in seperate files like test_simple.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pytest Code/test_simple1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to remember is that floating point arithmitic is not exact so the test of add02 in test_simple2.py fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pytest Code/test_simple2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this pytest had a function called `approx` which by default allows a relative tolerance of 1e-6 which is mostly fine and it works on most data objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import approx\n",
    "import numpy as np\n",
    "print(0.1 + 0.2 == approx(0.3))\n",
    "print((0.1 + 0.2, 0.2+0.4) == approx((0.3,0.6)))\n",
    "print({'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6}))\n",
    "print(np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == approx(np.array([0.3, 0.6])))\n",
    "print(np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if you are testing things near zero relative tolerances are useless.  Luckly `approx` also allows you to change the tolerances and make them relative or absolute.  If you specify both, it is true if either are satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import approx\n",
    "print(1.0001 == approx(1))\n",
    "print(1.0001 == approx(1, rel=1e-3))\n",
    "print(1.0001 == approx(1, abs=1e-3))\n",
    "print(1.0001 == approx(1, rel=1e-5, abs=1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify a specific failure message with `fail` ie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytest import fail\n",
    "def test_something():\n",
    "    x = somefunc()\n",
    "    if x in badthings:\n",
    "        fail('A bad thing came back from somefunc()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally note that if we specify no arguments `pytest` looks for files names `test_fimename` or `filename_test` and runs them.  In general is is best practice to put your source code and you tests in different directories as it keeps them seperate and safe.  You should have one test file for each module.  Then running pytest in the test directory will check all your code or you can run on individual modules if you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pytest Code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Game of life\n",
    "\n",
    "Write a small module that runs Conway's game of life, https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life.  You start with a 2D grid where the cells are either 'alive' or 'dead'.  Then the rules for stepping in time are:\n",
    "\n",
    "1. Overpopulation. Live cells with more than 3 neighbours dies\n",
    "2. Underpopulation. Live cells with less than 2 neighbours dies\n",
    "3. Reproduction. Dead cells with 3 neighbours becomes live\n",
    "\n",
    "Boundaries are periodic\n",
    "\n",
    "Your code should accept either a starting set of cells or dimensions for the board plus a number of iterations and output a plot of the game board at each step.\n",
    "\n",
    "Try to use debug to fix errors and design unit tests for each of your functions.  Don't forget to prototype and document your code.\n",
    "\n",
    "## Optimisation\n",
    "\n",
    "Often the code we initiially write to solve a problem is primarily focused on accuracy but often once this is achieved we find the code runs too slowly to be used in the way we want it to.\n",
    "\n",
    "In order to understand how to make code faster it can be useful to know the basics of how a computer works. Most computers have an architecture that looks a bit like this:\n",
    "\n",
    "![](Plots/Computer_architecture.png)\n",
    "\n",
    "Modern CPU's are so fast that actually most optimisatising for high performance computing comes from optimising memory usage to make sure the CPU is fed with enough data.  These are three numbers listed for each section in the above plot: Latency, which is how long it takes to respond to a command; Bandwidth, which is how past it can pass data up the chain; Size, which is how much data can be stored there.  The main problem we see is that memory latency is ~200 times longer than CPU latency (which is 1 cycle).  So, if you cant to multiple two numbers it takes 200 times as long to get them to teh CPU as it does to multiply them.  The response to this is to introduce multiple layers for faster and faster, but smaller and smaller, memory inbetween the CPU and main memory called 'cache'.  This helps keep data that we are working on close to the CPU so if we want to use it we can without delay.  This means that there are two things we can do to speed up our code.  Keep data local, ie near the CPU, and reuse it as much as possible while it is there.  Obviously you have no direct control over the cache but there are some things you can do that help the computer optimise this.\n",
    "\n",
    "The best analogy for a computer is trying to learn something from textbooks.  Now the heirarchy looks like this:\n",
    "\n",
    "![](Plots/Library.png)\n",
    "\n",
    "And it is easy to get some basic lessons\n",
    "\n",
    "- Get all the books you need from the library at once because it's a pain to keep going back there\n",
    "- Constantly swapping books is annoying so try to finish workng on the open ones before you look at the next set\n",
    "\n",
    "With this vauge idea in mind now lets look at some specifics cases.\n",
    "\n",
    "There are always many different ways to do the same calculation so you should get into the habit of checking which is fastest.  For simple commands and functions we can just use `%timeit` (single line) and `%%timeit` (entire cell) which are useful for comparing equvilent code.  The best bit is they run the code multiple times to give you an accurate estimate of time.  Here are some examples of simple speedups you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.9 ns ± 0.0794 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "57.3 ns ± 0.204 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "56.3 ns ± 0.248 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "56.6 ns ± 0.254 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "37.2 ns ± 0.513 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n",
      "9.09 ns ± 0.00444 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n",
      "34.1 ns ± 0.0437 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# 1. Squaring vs multiplication vs adding\n",
    "x = 0.5\n",
    "%timeit x**2\n",
    "%timeit x*x\n",
    "%timeit x/x\n",
    "\n",
    "%timeit x+x\n",
    "%timeit 2.0*x\n",
    "%timeit 2.0*5.0\n",
    "%timeit x/0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strictly speaking on a CPU addition is faster than multiplication which is faster than division.  Exponentiation is not a basic operation for teh CPU and instead takes the log then multiplies.  However, in python we see that while exponentiation is slower than multiplying, multipliing is the same as adding.  Multiplying by a number is faster than multiplying by a variable as we don't have to go and find the number it in memory and multipliing two numbers much faster again.  We can roughly conclude taht it takes twice as long to find a variable as it does to multiply it (you can read faster than find the right bit of a book). In python division and muliplication take the same time.  This is because most of the time is lost in finding the variables rather than the operation itself.  But if we do the operation alot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645 µs ± 1.73 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "684 µs ± 1.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [0.5*x for x in range(10000)]\n",
    "%timeit [x/2.0 for x in range(10000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then small differences can emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Square root\n",
    "import math\n",
    "%timeit x**0.5\n",
    "%timeit math.sqrt(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python functions can be slower than basic operations (in compiled code the reverse would usually be true).   I think here `sqrt` most likely has higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3a. Math vs Numpy\n",
    "import math\n",
    "import numpy as np\n",
    "%timeit math.sin(x)\n",
    "%timeit np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So numpy is slower for scalars but..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b. Math vs Numpy for vector\n",
    "X = np.random.random(100)\n",
    "Y1 = np.zeros(100)\n",
    "Y2 = np.zeros(100)\n",
    "Y3 = np.zeros(100)\n",
    "%timeit Y1 = np.sin(X)\n",
    "%timeit Y2 = list(map(lambda x: math.sin(x),X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    Y3[i] = math.sin(X[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is faster for arrays, note the tiny scaling which shows that almost all the time is getting the function itself so gain most of the time is in finding things, not calculation.  Here we have used `map` which is a way of applying a function to a list with the format:\n",
    "\n",
    "map(function,list) ie:  `list(map(lambda x: x**2, items)`\n",
    "\n",
    "There is also `filter` which selects based on a condition:\n",
    "\n",
    "filter(function,list) ie: `list(filter(lambda x: x < 0, items))`\n",
    "\n",
    "These are faster than loops but can't compete with numpy.   Here is something similar for matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 ns ± 4.44 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "45.4 ns ± 0.126 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# 4a. Math vs Numpy multiplication\n",
    "x=2.3\n",
    "y=3.4\n",
    "%timeit np.dot(x,y)\n",
    "%timeit x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 4b. Math vs Numpy for dot product\n",
    "X = np.random.random(100)\n",
    "Y = np.random.random(100)\n",
    "%timeit np.dot(X,Y)\n",
    "%timeit sum(list(map(lambda x:x[0]*x[1],list(zip(X,Y)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the call time for numpy is all the time and much faster than `map` construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.95 µs ± 55.4 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "28.8 µs ± 113 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# 5. Constructing lists\n",
    "%timeit [x*x for x in range(100)]\n",
    "%timeit [x**2 for x in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.63 µs ± 54.9 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "list1=[]\n",
    "for x in range(100):\n",
    "    list1.append(x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.66 µs ± 48.5 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "list1=[]\n",
    "append = list1.append\n",
    "for x in range(100):\n",
    "    append(x*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.2 µs ± 12.1 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "list1 = np.zeros((100))\n",
    "for x in range(100):\n",
    "    list1[x] = x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.81 µs ± 76.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.fromfunction(lambda i,:i*i,(100,),dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So list comprehensions are fastest. Also note that using `append = list1.append` saves us about 20% in time.  This is due to not having to looking up the function, the assignment has make it more 'local' in memory.  Do be careful with this as it can make code very hard to read if you do it alot.  Also note that subsequent operations on list1 may be quicker for the last 2 methods as the list is more likely to be contiguous in memory (all in the same place) for very large lists so we can read it to cache faster.   Finally, note that using a list comprehension won't make you code fast if you use bad algorithms like `x**2` rather than `x*x` which costs ~5 times as much.  In general better algorithms will always win over better code.  This is why prototyping is such a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Different indexing orders\n",
    "import numpy as np\n",
    "A = np.zeros((100,100))\n",
    "B = np.random.random((100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.74 ms ± 34.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        A[i,j] = B[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73 ms ± 18.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        A[j,i] = B[j,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In C or Fortran this would have mattered alot, but here the loops are so slow you don't see any difference due to how you are accessing memory.  This could still be something to try for very large arrays as it may eventually win.  The problem is that python stores arrays as a single line of all the rows in order so the `(i,j)` loop reads the data in order, so the next value is just next to the last one.  The `(j,i)` has to jump the lenght of the row to find the next value slowing it down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Move stuff out of loops if possible\n",
    "import math\n",
    "\n",
    "def func1():\n",
    "    x=math.sqrt(2)\n",
    "    y=0\n",
    "    for i in range(100):\n",
    "        y*=x\n",
    "        \n",
    "def func2():\n",
    "    y=0\n",
    "    for i in range(100):\n",
    "        y*=math.sqrt(2)\n",
    "        \n",
    "%timeit func1()\n",
    "%timeit func2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no point in working out the square root of 2 100 times. Again try to make stuff used in loops 'local' and avoid any calculation if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264 ns ± 2.73 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n",
      "222 ns ± 0.553 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "#8a. Move stuff out of loops if possible\n",
    "import math\n",
    "list1 = [range(100)]\n",
    "\n",
    "def func1():\n",
    "    y=0\n",
    "    i=0\n",
    "    while i<len(list1):\n",
    "        y+=i\n",
    "        i+=1\n",
    "        \n",
    "def func2():\n",
    "    y=0\n",
    "    i=0\n",
    "    length = len(list1)\n",
    "    while i<length:\n",
    "        y+=i\n",
    "        i+=1\n",
    "        \n",
    "%timeit func1()\n",
    "%timeit func2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same goes for test conditons for while loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. imports inside Vs outside of funtions\n",
    "\n",
    "import math\n",
    "def func1():\n",
    "    math.sin(0.3)\n",
    "    \n",
    "def func2():\n",
    "    import math\n",
    "    math.sin(0.3)\n",
    "    \n",
    "    \n",
    "%timeit func1()\n",
    "%timeit func2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be tempting to use imports inside functions so it looks tidy but this has significant cost. Best leave them at the top of the module as functions may be used multiple times but modules are (generally) only loaded once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Function overhead\n",
    "\n",
    "def func1(i):\n",
    "    return i*i\n",
    "\n",
    "def func2():\n",
    "    x = 0e0\n",
    "    for i in range(100):\n",
    "        x += func1(1)\n",
    "        \n",
    "def func3():\n",
    "    x = 0e0\n",
    "    for i in range(100):\n",
    "        x += i*i\n",
    "        \n",
    "%timeit func2()\n",
    "%timeit func3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modulisation is great but function calls can be expensive so don't go crazy (especially in loops!).  Again this is introducing an extra lookup which makes the data less likely to be local in cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Multiple assignment rather than tempory variables\n",
    "\n",
    "def func1():\n",
    "    a=0\n",
    "    b=1\n",
    "    for i in range(1000):\n",
    "        a,b = b,a+b\n",
    "        \n",
    "def func2():\n",
    "    a=0\n",
    "    b=1\n",
    "    for i in range(1000):\n",
    "        c = a+b\n",
    "        a = b\n",
    "        b = c\n",
    "        \n",
    "%timeit func1()\n",
    "%timeit func2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small saving (plus looks better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 12. Finding elements depends on the data type\n",
    "list1 = [range(100)]\n",
    "set1 = set(list1)\n",
    "\n",
    "%timeit 5 in list1\n",
    "%timeit 5 in set1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sets and dictionaries are hash tables so are faster to search than lists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 ms ± 21.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.3 ms ± 9.14 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "1.42 ms ± 6.32 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# 13. Read entire files at once if possible\n",
    "import numpy as np\n",
    "def read1():\n",
    "    data1 = np.loadtxt('Data/Period1.txt')\n",
    "    return data1\n",
    "\n",
    "def read2():\n",
    "    file = open('Data/Period1.txt','r')\n",
    "    data1 = []\n",
    "    for line in file:\n",
    "        tmp = line.split()\n",
    "        data1.append(float(tmp[0]))\n",
    "    data2 = np.array(data1)\n",
    "    return data2\n",
    "\n",
    "def read3():\n",
    "    file = open('Data/Period1.txt','r')\n",
    "    data1 = file.read()\n",
    "    data1 = data1.split('\\n')\n",
    "    data1 = [float(x) for x in data1[:-1]]\n",
    "    data1 = np.array(data1)\n",
    "    return data1\n",
    "\n",
    "%timeit read1()\n",
    "%timeit read2()\n",
    "%timeit read3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So numpy is the cleanest to code but the slowest to run and reading the file in one block is better than line by line (remember getting all library books at once rather than making multiple trips).  This is especially true on shared systems where you may compete for bandwidth for I/O.  There the system may alternate read statements from competing programmes eg: someone reads 1Tb, you read a line, someone reads 1Tb, you read one line etc.. which can be crippling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I could go on and on but it's impossible to list all the things to consider so how do we decide which bits of our code to focus on?  The answer is to profile your code and see which bits take the longest.\n",
    "\n",
    "### Profiliing\n",
    "\n",
    "Profilers analysis your code and tell you what parts are taking the most time (and memory) to run.  There are a few you can use.  Lets look at them with our little prim number generator we created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "def primenum(N):\n",
    "    primes = [2]\n",
    "    for n in range(3,N):\n",
    "        if all(n%p>0 for p in primes):\n",
    "            primes.append(n)\n",
    "    return primes \n",
    "\n",
    "%prun primenum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that we spent most of our time in `<genexp>` on line 4 with the next most time spent on the build in method `all`.  Which is what we would expect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we could install the `line_profiler` package (`conda install line_profiler`) and use this instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "def primenum(N):\n",
    "    primes = [2]\n",
    "    for n in range(3,N):\n",
    "        if all(n%p>0 for p in primes):\n",
    "            primes.append(n)\n",
    "    return primes \n",
    "\n",
    "\n",
    "%lprun -f primenum primenum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is a little easier to read.  As one of our main problems is likely to be memory useage we can also profile memory with the `memory_profiler` package (`conda install memory_profiler`) but this only works on files so we need to save this to a file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Tools/primetools.py\n"
     ]
    }
   ],
   "source": [
    "%%file Tools/primetools.py\n",
    "def primenum(N):\n",
    "    primes = [2]\n",
    "    for n in range(3,N):\n",
    "        if all(n%p>0 for p in primes):\n",
    "            primes.append(n)\n",
    "    return primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%load_ext memory_profiler\n",
    "import sys\n",
    "sys.path.append('./Tools') \n",
    "import primetools as pts \n",
    "%mprun -f pts.primenum pts.primenum(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `%run -p` to profile scripts that we run.  Finally there is also another build in profiler `cProfile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         797856 function calls in 0.151 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.005    0.005    0.151    0.151 <ipython-input-128-a151a3abc01c>:2(primenum)\n",
      "   786627    0.089    0.000    0.089    0.000 <ipython-input-128-a151a3abc01c>:5(<genexpr>)\n",
      "        1    0.000    0.000    0.151    0.151 <string>:1(<module>)\n",
      "     9997    0.056    0.000    0.145    0.000 {built-in method builtins.all}\n",
      "        1    0.000    0.000    0.151    0.151 {built-in method builtins.exec}\n",
      "     1228    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cProfile\n",
    "def primenum(N):\n",
    "    primes = [2]\n",
    "    for n in range(3,N):\n",
    "        if all(n%p>0 for p in primes):\n",
    "            primes.append(n)\n",
    "    return primes \n",
    "\n",
    "cProfile.run('primenum(10000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can also be run from the command line with `python -m cProfile [-o output_file] [-s sort_order] myscript.py` which is usefull\n",
    "\n",
    "Exercise:\n",
    "\n",
    "Profile your 'game of life' code and see if you can get it to run any faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
