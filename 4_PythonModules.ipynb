{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JamesFergusson/Introduction-to-Research-Computing/blob/master/4_PythonModules.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules\n",
    "\n",
    "Ok, so now we have a basic understanding of Python and how to write codes that perform simple calculations.  One key part is that we can write functions for sections of code we want to use multiple times.  This also helps us to keep our main code simple to understand by keeping it short as detailed calculating can be moved to functions instead.  Take the example of calculating the integral of three legendre functions up to some $l_{max}$\n",
    "\n",
    "$\\int_{-1}^1 P_{l_1}(\\mu) P_{l_2}(\\mu) P_{l_3}(\\mu) d\\mu$\n",
    "\n",
    "Here is some (quite bad) code to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmax = 2\n",
    "\n",
    "lmax += 1\n",
    "lvec = [l for l in range(lmax)]\n",
    "xmax = lmax*10\n",
    "xvec = [(2e0*x/(xmax-1))-1 for x in range(xmax)]\n",
    "\n",
    "legendre = []\n",
    "for x in xvec:\n",
    "    pt = [1,x]\n",
    "    for i in lvec[2:]:\n",
    "        y = ((2*i-1)/(i))*pt[i-1]*x - ((i-1)/i)*pt[i-2]\n",
    "        pt.append(y)\n",
    "    legendre.append(pt)\n",
    "\n",
    "for l1 in lvec:\n",
    "    for l2 in lvec[l1:]:\n",
    "        for l3 in lvec[l2:]:\n",
    "            y1 = legendre[0][l1]*legendre[0][l2]*legendre[0][l3]\n",
    "            x1 = xvec[0]\n",
    "            int = 0e0\n",
    "            for i, x in enumerate(xvec[1:]):\n",
    "                y2 = legendre[i][l1]*legendre[i][l2]*legendre[i][l3]\n",
    "               m x2 = x\n",
    "                int += 0.5*(y2+y1)*(x2-x1)\n",
    "                y1 = y2\n",
    "                x1 = x2\n",
    "            print(l1,l2,l3,int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add some functions to simplify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(lmax):\n",
    "    lmax += 1\n",
    "    lvec = [l for l in range(lmax)]\n",
    "    xmax = lmax*10\n",
    "    xvec = [(2e0*x/(xmax-1))-1 for x in range(xmax)]\n",
    "    return xvec, lvec\n",
    "\n",
    "def create_legendre(xvec,lvec):\n",
    "    legendre = []\n",
    "    for x in xvec:\n",
    "        pt = [1,x]\n",
    "        for i in lvec[2:]:\n",
    "            y = ((2*i-1)/(i))*pt[i-1]*x - ((i-1)/i)*pt[i-2]\n",
    "            pt.append(y)\n",
    "        legendre.append(pt)\n",
    "    return legendre\n",
    "\n",
    "def integrate(l1,l2,l3,xvec,legendre):\n",
    "    y1 = legendre[0][l1]*legendre[0][l2]*legendre[0][l3]\n",
    "    x1 = xvec[0]\n",
    "    int = 0e0\n",
    "    for i, x in enumerate(xvec[1:]):\n",
    "        y2 = legendre[i][l1]*legendre[i][l2]*legendre[i][l3]\n",
    "        x2 = x\n",
    "        int += 0.5*(y2+y1)*(x2-x1)\n",
    "        y1 = y2\n",
    "        x1 = x2\n",
    "    return int\n",
    "    \n",
    "# ************** Main code **************\n",
    "lmax = 2\n",
    "\n",
    "xvec, lvec = create_vectors(lmax)\n",
    "\n",
    "L = create_legendre(xvec,lvec)\n",
    "\n",
    "for l1 in lvec:\n",
    "    for l2 in lvec[l1:]:\n",
    "        for l3 in lvec[l2:]:\n",
    "            int = integrate(l1,l2,l3,xvec,L)\n",
    "            print(l1,l2,l3,int)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is easier to understand but the long lists of functions at the start make it harder to see what is happening (and find the 'main' part).\n",
    "\n",
    "As we start to write more and more complicated codes we will soon find that then number of functions we create becomes too much to keep in the main python file and still be easily readable.  The way to deal with this is to move the functions into modules.  A module is just a .py file which contains the functions.  Create a file called leg_tools.py in the Tools directory and copy the functions into it.  Now we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./Tools/') #We will look at this later, it just makes sure the interpreter can find the file\n",
    "\n",
    "import leg_tools as lg\n",
    "\n",
    "lmax = 2\n",
    "\n",
    "xvec, lvec = lg.create_vectors(lmax)\n",
    "\n",
    "L = lg.create_legendre(xvec,lvec)\n",
    "\n",
    "for l1 in lvec:\n",
    "    for l2 in lvec[l1:]:\n",
    "        for l3 in lvec[l2:]:\n",
    "            int = lg.integrate(l1,l2,l3,xvec,L)\n",
    "            print(l1,l2,l3,int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is known as modular programming.  It makes the code easier to read, more resuable and easier to debug as you can test the modules seperatly.  Once you start writing alot of code you may want to begin creating packages, which are just sets of modules.   This is very easy.  You just put all the modules files in a directory then create an empty file called `__init__.py` in the directory (this file can contain initilisation code for the package but blank is fine).  Try this with out `Tools` directory then try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 2.0\n",
      "0 0 1 -0.13555291319857335\n",
      "0 0 2 0.009266472590102048\n",
      "0 1 1 0.6728443150600679\n",
      "0 1 2 -0.12913962060340942\n",
      "0 2 2 0.4171535197760008\n",
      "1 1 1 -0.13127738480179732\n",
      "1 1 2 0.28119117071403454\n",
      "1 2 2 -0.12400746136851618\n",
      "2 2 2 0.13821157249435442\n"
     ]
    }
   ],
   "source": [
    "from Tools import leg_tools as lg\n",
    "\n",
    "lmax = 2\n",
    "\n",
    "xvec, lvec = lg.create_vectors(lmax)\n",
    "\n",
    "L = lg.create_legendre(xvec,lvec)\n",
    "\n",
    "for l1 in lvec:\n",
    "    for l2 in lvec[l1:]:\n",
    "        for l3 in lvec[l2:]:\n",
    "            int = lg.integrate(l1,l2,l3,xvec,L)\n",
    "            print(l1,l2,l3,int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have some lovely readable code in a nice modular structure.  The `import` command has the following possible structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math         # now we can use, for example, sin with                        >> math.sin(x)\n",
    "import math as mt   # 'math' takes too long to type, now we only need              >> mt.sin(x)\n",
    "from math import sin  # I'm very busy and important, I don't have time for 'mt.'   >> sin(x)\n",
    "from math import *  # That was great, I'll do it with everything in math!          >> sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two are both equivalent but the second needs less typing. The third points sin to math.sin which is ok but the second is better. The last should never be used.  This is because there can be clashes with function names in different modules so if you put everything in the namespace you can get unexpected behaviour, for example python has a function `sum` but so does `numpy` and they take different arguments.  `tab` completion makes typing long things easy anyway so it's unessecary.  Please stick to the second and use sensible aliases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that while we have only been looking at python the basic structure of most programming languages is roughly the same.  They all have a set of data types (`int`, `float`, `string` and sometimes `complex`) and have an `if`, `for` and `while` structures and often a compressed version of each (like we saw in list comprehensions).  They also always support `functions` and `subroutines` in a modular structure where we move often used blocks of code into seperate files then import them to the main programme.  Here is a quick comparison to illustate the point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***  Python  ***                       ***    C    ***                       *** Fortran ***\n",
    "#******************************************************************************************************************\n",
    "#  Basic types:\n",
    "#****************************************************************************************************************** \n",
    "# a = 1                                  int a = 1;                            INTEGER :: a = 1\n",
    "# x = 1.0                                double x = 1.0;                       REAL(DP) :: x = 1.0\n",
    "# s = 'cat'                              char s[180] = \"cat\";                  CHARACTER(len=180) :: s = \"cat\"\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#  For loops:\n",
    "#******************************************************************************************************************\n",
    "# for n in range(10):                    for(i=0;i<10;i++){                    DO n=0,9\n",
    "#     'do something'                         'do something';                      'do something'\n",
    "#                                        }                                     END DO\n",
    "\n",
    "#******************************************************************************************************************\n",
    "#  Conditionals:\n",
    "#******************************************************************************************************************\n",
    "# if n<10:                               if(n<10){                             IF (n<10) THEN\n",
    "#     'stuff1'                               'stuff1';                             'stuff1'\n",
    "# elif n<20:                             } else if (n<20) {                    ELSE IF (n<20)\n",
    "#     'stuff2'                               'stuff2';                             'stuff2'      \n",
    "# else:                                  } else {                              ELSE\n",
    "#     'stuff3'                               'stuff3';                             'stuff3'  \n",
    "#                                        }                                     END IF\n",
    "\n",
    "#******************************************************************************************************************\n",
    "# Function in module file:\n",
    "#******************************************************************************************************************\n",
    "# def function1(i,x)                     #include <math.h>                     MODULE module1\n",
    "#    return x**i                         double function1(int i, double x){        SUBROUTINE function1(i,x,y) \n",
    "#                                            return pow(x,i);                          INTEGER :: i\n",
    "#                                        }                                             REAL(DP) :: x,y\n",
    "#                                                                                      y = x**i\n",
    "#                                                                                  END SUBROUTINE\n",
    "#                                                                              END MODULE\n",
    "\n",
    "#******************************************************************************************************************\n",
    "# Using function from module file:\n",
    "#******************************************************************************************************************\n",
    "# import module1 as mod1                #include \"module1\"                     PROGRAM MAIN\n",
    "# x = mod1.function1(2.0,3)             int main( int argc, char *argv[] ){        USE module1\n",
    "# print(x)                                  double x = function1(2.0,3);           REAL(DP) :: x\n",
    "#                                           printf(\"%e\\n\",x);                      CALL function1(2.0,3,x)\n",
    "#                                       }                                          WRITE(*,*) x\n",
    "#                                                                              END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can see clear similarities between the languages.  The key differences between python and  C and Fortran are that you have to declare what each of your variables are, they are both much more explicit in their structure and they both need to be 'compiled' to work\n",
    "\n",
    "\n",
    "The other main difference is that native python generally runs, depending on the task, 100x to 1000x slower than the equivalent compiled code in C or Fortran.  This is the trade off for having flexable types and simple syntax.  The interpreter has to spend alot of time checking exactly what it needs to do to run the code.  In compiled languages you have to be very explicit about what you are doing so the computer can just get on with the calculation and the code runs faster.  Also they are compiled, which means run though a programme to produce an executable (thing you can run, or execute), and during this process the compiler will optimise the code for the particular chipset you are using.  \n",
    "\n",
    "This seems pretty terrible at first, why would you want to bother leaning a language that performs so badly?  Well the answer is that you can keep all the convenience of python but have comparable speeds by using optimised modules or packages to perform the heavy lifting.  For instance simply deciding to use the numerical package `numpy` (which we will meet in a second) can reduce runtimes by ~100x.  This is because almost all the python packages we use are actually written in C and Fortran (you can check this with the `??` command. This will return the python code for the function if possible.  If it returns just the documentation, like `?`, then the function is written in another language).  You can then think of python as a simple way of accessing the performance of compiled code without the hassel of having to write it.  It also gives us the first rule for writing code which is simply:\n",
    "\n",
    "<b> Bad artists copy, Great artists steal</b>\n",
    "\n",
    "Most numerical libraries will have been written by a team of experts and carefully tested and optimised. They will write much better code than you can so always use theirs for standard operations if possible.\n",
    "\n",
    "Right, with that in mind let's look at the most useful modules for python\n",
    "\n",
    "## Standard Library\n",
    "\n",
    "Python3 has a standard library of modules you can import (see: https://docs.python.org/3/library/). These cover most of the basic stuff you could want to.  Some useful ones are: `sys`, `itertools`,`random`, `math/cmath`. We already used `sys.path` to add our module directory to the path so python could find it near the beginning of this notebook.  This is probably the most useful function in it, the rest are pretty obscure.\n",
    "\n",
    "`itertools` is more fun.  It has lots of interesting iterators you can play with like `count`, `permutations`, `combinations` and `product`.  There names are pretty self explanitory but here are some examples of them in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "(1, 2, 3) (1, 3, 2) (2, 1, 3) (2, 3, 1) (3, 1, 2) (3, 2, 1)\n",
      "(1, 2) (1, 3) (1, 4) (1, 5) (2, 3) (2, 4) (2, 5) (3, 4) (3, 5) (4, 5)\n",
      "(1, 2) (1, 3) (1, 4) (2, 2) (2, 3) (2, 4) (3, 2) (3, 3) (3, 4)\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "from itertools import permutations\n",
    "from itertools import combinations\n",
    "from itertools import product\n",
    "\n",
    "for i in count():\n",
    "    if i>10:\n",
    "        break\n",
    "    print(i)\n",
    "\n",
    "perm = permutations([1,2,3])\n",
    "comb = combinations([1,2,3,4,5],2) \n",
    "prod = product([1,2,3],[2,3,4])\n",
    "\n",
    "print(*perm)\n",
    "print(*comb)\n",
    "print(*prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`random` gives you random number generators. `math` contains most standard mathematical functions (see:https://docs.python.org/3/library/math.html) which are good for single values, `cmath` is the same for complex numbers.  If you want to use them on all elements in a large array `numpy` is much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy\n",
    "\n",
    "Numpy (<b>Num</b>erical <b>py</b>thon) is primarily for creating and performing calculations on arrays and as such is fundamental to most data science applications (python does have an `array` module as standard but numpy is better).  It is almost always imported as `np`.\n",
    "\n",
    "### Creation\n",
    "Let's begin by creating arrays which are just $N$ dimensional objects of a single type. The 'single type' constraint is worth remembering.  Trying to put floats into interger arrays, or complex numbers to either will not upcast like with single variables.\n",
    "\n",
    "There are alot of ways to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2 3]\n",
      " [2 3 4]\n",
      " [3 4 5]]\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "[[1 1 1 1]\n",
      " [1 1 1 1]\n",
      " [1 1 1 1]]\n",
      "[[3.14 3.14 3.14 3.14]\n",
      " [3.14 3.14 3.14 3.14]\n",
      " [3.14 3.14 3.14 3.14]]\n",
      "[ 1 24 47 70 93]\n",
      "[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667\n",
      " 2.        ]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "[[0.49415086 0.67067159 0.26041264 0.74470802]\n",
      " [0.59281468 0.90306403 0.01876179 0.28442661]\n",
      " [0.71301036 0.34868027 0.14613947 0.9995564 ]]\n",
      "[[-14.09927435  -0.04231117   8.36412711   1.98202748]\n",
      " [  0.10364214   1.86704544   0.47434965  -0.19864777]\n",
      " [  0.83918561  -7.97059071  -3.9369512    4.07400993]]\n",
      "[[4 8 6 3]\n",
      " [8 4 4 7]\n",
      " [6 5 8 6]]\n",
      "[[2.68156159e+154 2.68156159e+154 2.21910068e-314 2.21739775e-314]\n",
      " [2.21912866e-314 2.21739734e-314 2.21912803e-314 2.21739906e-314]\n",
      " [2.21912803e-314 2.21858457e-314 2.21912749e-314 2.21912866e-314]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4,5])                    # From a list\n",
    "b = np.array([[1,2],[3,4]])                  # From a list of a list\n",
    "c = np.array([range(i,i+3) for i in [1,2,3]])# From a list comprehension\n",
    "z = np.zeros((3,4), dtype='int')             # 3x4 array of integer zeros\n",
    "o = np.ones((3,4), dtype='float')            # 3x4 array of float ones\n",
    "o = np.ones_like(z)                          # z shaped array of ones\n",
    "p = np.full((3,4), 3.14)                     # 3x4 array of 3.14\n",
    "m = np.arange(1,100,23)                      # Like range count from 1 in multiples of 23 until 100\n",
    "n = np.linspace(0,2,7)                       # 7 values linearly spaced from 0 to 2\n",
    "i = np.eye(4)                                # 4x4 Identity\n",
    "\n",
    "#*** Random arrays ***\n",
    "r1 = np.random.random((3,4))                 # 3x4 Random numbers between 0-1\n",
    "r2 = np.random.normal(0,5,(3,4))             # 3x4 Random numbers normal distributed with mean 0 and stdev 5\n",
    "r3 = np.random.randint(3,9,(3,4))            # 3x4 Random integrers between 3-9\n",
    "\n",
    "#*** Blank arrays ***\n",
    "k = np.empty((3,4))                          # 3x4 array with unallocated entries (just the memory reserved)\n",
    "l = np.empty_like(b)                         # Empty array with dimensions same as 'b'\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(z)\n",
    "print(o)\n",
    "print(p)\n",
    "print(m)\n",
    "print(n)\n",
    "print(i)\n",
    "print(r1)\n",
    "print(r2)\n",
    "print(r3)\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete an array after you have finished with it simply use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But beware the array won't go anywhere if you still have variables that point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=b\n",
    "print(b,c)\n",
    "b=None\n",
    "print(b,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command doesn't actually delete the array but just unreferences it.  The python garbage collector should then come along and clean it up so don't expect the memory use to come down immediately.  Try to get into the habit of doing this with all arrays after you finish with them,  this stops 'memory leaks' which can slow down your code.\n",
    "\n",
    "### Accessing elements\n",
    "Once you have created an array you access the elements in the obvious way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([range(i,i+5) for i in [1,6,11,16,21]])\n",
    "print(M,'\\n')\n",
    "print(M[1,1],M[1,3],M[-1,-1],M[-1,2],'\\n')   # Accessing individual elements\n",
    "M[2,2] = 100                                 # Changing elements\n",
    "print(M,'\\n')             \n",
    "M[2,2] = 3.1415927                           # Beware! numpy won't up-cast an array, it will down-cast your input\n",
    "print(M,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can of course access subarrays easily using the colon notation we met earlier in lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(M[1:3,1:3],'\\n')  # central sub array\n",
    "print(M[:3,2:],'\\n')    # top right sub array\n",
    "print(M[:,0:5:2],'\\n')  # only even columns\n",
    "print(M[::-1,:],'\\n')   # reverse the rows (you can neglect the `,:` after `::-1` here but please don't)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  Assigining this to something does not create a new array with the sub-array, it just maps that part of the array to a new object so editing an entry affects both arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[range(i,i+5) for i in range(j,j+25,5)] for j in range(1,125,25)] )\n",
    "print(M,'\\n*****************')\n",
    "N = M[1:4,1:4,1:4]\n",
    "print(N,'\\n*****************')\n",
    "N[1,1,1] = 1000\n",
    "print(N,'\\n*****************')\n",
    "print(M,'\\n*****************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actualy copy the sub array we must use `.copy()`, ie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[range(i,i+5) for i in range(j,j+25,5)] for j in range(1,125,25)] )\n",
    "N = M[1:4,1:4,1:4].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our code to create the original array `M` in the above example looks a bit complicated for a matrix with a fairly simple pattern.  Matricies like these can be more easily generated by taking a vector and using the `reshape` command ie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.arange(1,126).reshape((5,5,5))\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More usefully this is good for converting n-dim 1D arrays to nx1-dim 2D arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.arange(10)\n",
    "print(M)\n",
    "N = M.reshape(1,10)\n",
    "print(N)\n",
    "N = M.reshape(10,1)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining and spliting arrays\n",
    "You can also join and split arrays.  To join them you use `concatenate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([1,2,3])\n",
    "B = np.array([4,5,6])\n",
    "print(np.concatenate([A,B]))\n",
    "A = A.reshape(1,3)\n",
    "B = B.reshape(1,3)\n",
    "print(np.concatenate([A,B]))\n",
    "print(np.concatenate([A,B],axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For joining arrays with different dimensions (ie adding a row to a matrix) there are three special commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "v1 = np.array([9,10,11,12])\n",
    "v2 = np.array([[13,14,15]])\n",
    "v3 = np.random.randint(0,20,(3,5))\n",
    "print(A)\n",
    "A = np.vstack([A,v1])   # Vertical stack, a bit like .append for lists\n",
    "print(A)\n",
    "A = np.hstack([A,v2.T]) # Horizontal stack (.T does the transpose)\n",
    "print(A)\n",
    "A = np.dstack([A,v3])   # Depth stack\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting arrays works in the same way using `split`.   Here `split(A,2)` splits the matrix into two equal halves and `split(A,[2])` splits the matrix at row 2.  `split[A,[2],axis=1]` splits the matrix on column 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(20).reshape(4,5)\n",
    "print(A)\n",
    "B,C = np.split(A,2)\n",
    "print(B)\n",
    "print(C)\n",
    "B,C = np.split(A,[2],axis=1)\n",
    "print(B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again we have `vsplit`,`hsplit` and `dsplit` variants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(20).reshape(4,5)\n",
    "print(A)\n",
    "B,C = np.vsplit(A,2)\n",
    "print(B)\n",
    "print(C)\n",
    "B,C = np.hsplit(A,[2])\n",
    "print(B)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise Calculation\n",
    "Numpy has a very large number of elementwise operators for arrays.  Firstly, it understands all the standard math operators for numbers in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace(1,2,9).reshape(3,3)\n",
    "B = np.linspace(-2,-1,9).reshape(3,3)\n",
    "print(A+B)\n",
    "print(A-B)\n",
    "print(A*B)\n",
    "print(A/B)\n",
    "print(A//B)\n",
    "print(A**B)\n",
    "print(A%B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also a large array of functions that can be applied elementwise (check here for a list https://docs.scipy.org/doc/numpy/reference/ufuncs.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace(-1,0.1,5)\n",
    "print(abs(A))\n",
    "print(np.sin(A))\n",
    "print(np.arccos(A))\n",
    "print(np.exp(A))\n",
    "print(np.log(abs(A)))\n",
    "print(np.reciprocal(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  There are two useful ones, `np.expm1` and `log1p` which calculate $e^x-1$ and $\\ln(x+1)$ which could otherwise be numerically unstable for small input.\n",
    "\n",
    "For more information<b> you can search numpy documentation! </b> With so many functions and commands it can be hard to use `tab` completion to find the one you want.  Here you can use the function `np.lookfor()` which searches all the documentation for whatever string you enter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.lookfor('dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Algebra\n",
    "The bread and butter of alot of numerical work is linear algebra.  Numpy has all the basic commands you would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[5,1,2],[2,5,1],[1,2,6]])\n",
    "B = np.linspace(6,12,6).reshape(3,2)\n",
    "print('dot product\\n',np.dot(A,B))\n",
    "print('Matrix product\\n',np.matmul(A,B))\n",
    "print('Inner product\\n',np.inner(A,A))\n",
    "print('Outer product\\n',np.outer(A,B))\n",
    "print('Trace\\n',np.trace(A))\n",
    "print('Transpose\\n',A.T)\n",
    "print('Matrix Power\\n',np.linalg.matrix_power(A,2))\n",
    "print('Inverse\\n',np.linalg.inv(A))\n",
    "print('Singular Value Decomposition\\n',np.linalg.svd(A))\n",
    "print('Determinant\\n',np.linalg.det(A))\n",
    "print('Eigen decomposition\\n',np.linalg.eig(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `dot` and `matmul` is only for arrays with dimension $N>2$. `np.dot(A,B)` is a sum product over the last axis of A and the second-to-last of B and `matmul(A,B)` is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.  There is also the more general `tensordot` and `einsum` for more general products.\n",
    "\n",
    "It can also solve linear equations for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace(1,6,9).reshape(3,3)\n",
    "b = np.linspace(2,5,3)\n",
    "print(np.linalg.solve(A,b))           # Straight linear solve \n",
    "C = np.linspace(1,4,12).reshape(3,4)\n",
    "d = np.linspace(2,4,3)\n",
    "print(np.linalg.lstsq(C,d,rcond=-1))  # Least squares solve for under or over determined systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also has aggregator functions which are good for statistics of the arrays. They can be applied to the whole array or just along particular dimensions with the `axis` argument.  Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace(0,1,16).reshape(4,4)\n",
    "print('sum:          ',np.sum(A))\n",
    "print('product:      ',np.prod(A))\n",
    "print('mean:         ',np.mean(A))\n",
    "print('sdt dev:      ',np.std(A))\n",
    "print('variance:     ',np.var(A))\n",
    "print('minimum:      ',np.min(A))\n",
    "print('maximum:      ',np.max(A))\n",
    "print('median:       ',np.median(A))\n",
    "print('index of min: ',np.argmin(A))\n",
    "print('index of max: ',np.argmax(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that annoyingly the `argmin` and `argmax` only return the flattened indexes not coordinates.  To fix this you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.linspace(0,1,16).reshape(4,4)\n",
    "print('index of min: ',np.unravel_index(np.argmin(A), A.shape))\n",
    "print('index of min: ',np.unravel_index(np.argmax(A), A.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main point to take from this section is that when dealing with arrays you should <b> never </b> loop over them unless it is completely unavoidable.  Python loops are notoriously slow so you are always better to use compiled routines from a package if possible.\n",
    "\n",
    "### Broadcasting\n",
    "Numpy had one further trick with arrays called broadcasting which allows you to perfom binary operations on matricies of different dimensions (dimension of size 1 don't count).  The rules for broadcasting are roughly that the lower dimensional array is copied until the dimensions agree. This sounds tricky but the process is easy to understand by example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones((4,4))\n",
    "B = np.arange(4).reshape(1,4)\n",
    "C = np.ones((2,4,4))\n",
    "print('Add scalar to matrix\\n',A+5)\n",
    "print('Add vector to matrix\\n',A+B)\n",
    "print('Add vector to 3D arr\\n',B+C)\n",
    "print('Add vector to column\\n',B+B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This initially doesn't sound very useful but it can be quite helpful.  Here are two examples\n",
    "\n",
    "1. Subtracting the mean\n",
    "\n",
    "Suppose we have made 10 measuements for 3 variables and we want to remove the bias from each one.  We know their average should be zero so we can just subtract of the mean as a first approximation.  We can represent the data as a 3x10 array and the bias as a 3 vector.  With broadcasting we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.array([[1,2,3],[2,3,4],[3,4,5],[4,5,6],[5,6,7],[6,7,8],[7,8,9],[9,0,1],[0,1,2],[1,2,3]])\n",
    "V = D.mean(0)\n",
    "D = D-V\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluating a function\n",
    "\n",
    "Suppose we have a function we want to evaluate on a grid (maybe for a plot).  Here we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-2,2,5)\n",
    "Y = np.linspace(-2,2,5).reshape(5,1)\n",
    "Z = X**3 + 4*X**2*Y + 5*X*Y**2 + 2*Y**3\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of other operations you can with numpy arrays that are worth noting as they are not obvious.  The first is that contitionals can operate element-wise to produce boolean arrays, eg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(16).reshape(4,4)\n",
    "print('Eg1\\n',A<6)\n",
    "print('Eg2\\n',A%2==0)\n",
    "print('Eg3\\n',A*3==A**2)\n",
    "print('Eg4\\n',A*(A%3==0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to select elements (which are returned in a 1D array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(16).reshape(4,4)\n",
    "print('Eg1\\n',A[A<6],'Count',np.sum(A<6))\n",
    "print('Eg2\\n',A[A%2==0],'Any?',np.any(A%2==0))\n",
    "print('Eg3\\n',A[A*3==A**2],'All?',np.all(A*3==A**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do element-wise `if` statements using `np.where`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(16).reshape(4,4)\n",
    "print(np.where(A%2==0,A,-A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second is that you can pass arrays as indexes to arrays so we can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.arange(16).reshape(4,4)\n",
    "B = np.array([1,3])\n",
    "C = np.array([0])\n",
    "D = np.array([[0,2],[1,3]])\n",
    "print('Eg1\\n',A[:,B])\n",
    "print('Eg2\\n',A[B,B])\n",
    "B = B[:,np.newaxis]     # Increase dimension by 1\n",
    "print('Eg3\\n',A[B,B.T])\n",
    "print('Eg4\\n',A[D,D])   # Think about this...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the point of these operations is to avoid using loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy\n",
    "\n",
    "Scipy package is build on numpy and is designed to perform more complicated analysis.  It has the following modules:\n",
    "\n",
    "- scipy.cluster ::  Vector quantization / Kmeans\n",
    "- scipy.constants ::  Physical and mathematical constants\n",
    "- scipy.fftpack  ::   Fourier transform\n",
    "- scipy.integrate  :: Integration routines\n",
    "- scipy.interpolate ::  Interpolation\n",
    "- scipy.io Data ::  input and output\n",
    "- scipy.linalg  :: Linear algebra routines\n",
    "- scipy.ndimage ::  n-dimensional image package\n",
    "- scipy.odr  :: Orthogonal distance regression\n",
    "- scipy.optimize ::  Optimization\n",
    "- scipy.signal ::  Signal processing\n",
    "- scipy.sparse ::  Sparse matrices\n",
    "- scipy.spatial ::  Spatial data structures and algorithms\n",
    "- scipy.special ::  Any special mathematical functions\n",
    "- scipy.stats ::  Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't go into the detail on all the above but leave you to play around a bit.  It is mainly build on numpy so all the stuff above works in a similar way. I do have some small comments thought on choosing routines which we will come back to later: \n",
    "\n",
    "1. It is always tempting as mathematicians to try to use sophisticated routines for tasks, like numerical integration for example, rather than simple ones we learn in school.  While these may be more mathematically effient they can often be computationaly inefficent.  Simple routines, like the trapazoidal rule, can be faster than more sophisticated routines even when you use 10x as many points.  This is because simple routines are easier to process and often 'vectorise' (we will come to this later, here just read 'uses the CPU better').  If in doubt aways use `%timeit` to check the speed difference between options, you may be suprised.\n",
    "\n",
    "2. Where there are multiple modules that can do the same task (like numpy vs scipy for linear algebra) profile both for you task (with realistic sizes) to see which one to use. Don't assume that one package is better than any other.\n",
    "\n",
    "Finally you can see http://www.scipy-lectures.org for (a lot) more information.\n",
    "\n",
    "### Exercises\n",
    "\n",
    "Suppose you net to create a set of $N$ orthonormal polynomials with respect to $\\left<P_{n} P_{m} \\right> = \\int_0^1 P_{n}(x) P_{m}(x) W(x) dx$ where the weight function is $W(x) = \\sin(\\ln (x+1))$.\n",
    "\n",
    "1. Start by calculating the correlation matrix, $M _{nm}= \\left<x^n x^m\\right>$, up to degree 5.\n",
    "2. Diagonalise this matrix to produce the coefficents (Any decomposition where the matrix becomes $\\lambda\\lambda^T$ works.  Cholesky will mimic Gram-Schmitt Orthonormalisation so is a good choice.) for the polynomials $M = \\lambda_{ij}$ where $P_i = \\sum_{j} \\lambda_{ij} x^j$, then check that the polynomials $P_n(x)$ are indeed orthonormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas (and h5py)\n",
    "\n",
    "Numpy mainly handles arrays some of you may need to work with structured data?  Numpy does have a structured array option but you are better off using Pandas (which comes from \"panel data\" used in econometrics, and because pandas are cute).\n",
    "\n",
    "If we think of Numpy as being mainly about arrays Pandas is mainly about DataFrames which is just an array with mixed data types and row/column labels (think spreadsheet).  It is generally imported as `pd`.  We won't spend much time on it, just have a quick look at the basic objects in case you think they would help with your work.  I'll leave you to discover all the detail on your own.\n",
    "\n",
    "Let's look at the basic objects, starting with `Series` (note the annoying capital letter for Series, python is case sensitive so you have to have it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    a\n",
      "2    3\n",
      "dtype: object\n",
      "[1 'a' 3]\n",
      "RangeIndex(start=0, stop=3, step=1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1,'a',3])\n",
    "print(data)\n",
    "print(data.values)\n",
    "print(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we get both the data and the index when we print it.  Here the index is the label so it is a bit like a dictionary.  You can specify what the labels are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "2    b\n",
      "c    3\n",
      "4    d\n",
      "e    5\n",
      "6    f\n",
      "g    7\n",
      "8    h\n",
      "dtype: object\n",
      "[1 'b' 3 'd' 5 'f' 7 'h']\n",
      "Index(['a', 2, 'c', 4, 'e', 6, 'g', 8], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1,'b',3,'d',5,'f',7,'h'],index=['a',2,'c',4,'e',6,'g',8])\n",
    "print(data)\n",
    "print(data.values)  # this just gives back the numpy array\n",
    "print(data.index)   # this gived just the indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the data just the same as in `numpy` but now with either with indexes or positions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "f    6\n",
      "dtype: int64\n",
      "c    3\n",
      "d    4\n",
      "e    5\n",
      "f    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([1,2,3,4,5,6,7,8],index=['a','b','c','d','e','f','g','h'])\n",
    "print(data[4])\n",
    "print(data['e']) \n",
    "print(data[2:6])\n",
    "print(data['c':'f'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if you use integers for index labels it gets a bit confused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "6    c\n",
      "5    d\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series(['a','b','c','d','e','f','g','h'],index=[8,7,6,5,4,3,2,1])\n",
    "print(data[8])   # Uses the label, this is the 'explicit' index\n",
    "print(data[2:4]) # Uses the position, this is the 'implicit' index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Series` objects can also be created like a dictionary or part thereof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    8\n",
      "b    7\n",
      "c    6\n",
      "d    5\n",
      "e    4\n",
      "f    3\n",
      "g    2\n",
      "h    2\n",
      "dtype: int64\n",
      "a    8\n",
      "b    7\n",
      "g    2\n",
      "h    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series({'a':8,'b':7,'c':6,'d':5,'e':4,'f':3,'g':2,'h':2})\n",
    "print(data)   \n",
    "data = pd.Series({'a':8,'b':7,'c':6,'d':5,'e':4,'f':3,'g':2,'h':2},index=['a','b','g','h'])\n",
    "print(data) # Uses the position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far not too interesting.  More use is the `DataFrame` object which is just the 2D version of `Series` (there are also 3d and 4d objects called `Panel` and `Panel4d` respectivly but we won't discuss them here).  We can create them in a number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ser1  ser2\n",
      "a     8     3\n",
      "b     7     5\n",
      "c     6     7\n",
      "d     5     9\n",
      "e     4    11\n",
      "f     3    13\n",
      "g     2    15\n",
      "h     2    17\n",
      "   ser1  ser2\n",
      "0     0     0\n",
      "1     2     1\n",
      "2     4     4\n",
      "3     6     9\n",
      "4     8    16\n",
      "   col1  col2\n",
      "a     8     6\n",
      "b     7     2\n",
      "c     8     8\n",
      "d     4     6\n",
      "e     6     9\n"
     ]
    }
   ],
   "source": [
    "ser1 = pd.Series({'a':8,'b':7,'c':6,'d':5,'e':4,'f':3,'g':2,'h':2})\n",
    "ser2 = pd.Series({'a':3,'b':5,'c':7,'d':9,'e':11,'f':13,'g':15,'h':17})\n",
    "data = pd.DataFrame({'ser1':ser1,'ser2':ser2}) # Combining series\n",
    "print(data)\n",
    "data = pd.DataFrame({'ser1':2*i,'ser2':i**2} for i in range(5)) # List comprehension\n",
    "print(data)\n",
    "data = pd.DataFrame(np.random.randint(0,10,(5,2)),columns=['col1','col2'],index=['a','b','c','d','e']) # from array\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are starting to look more like spreadsheets. Again we can access elements in an analogous way to `Series` objects (but naive numpy things don't work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "a     5     7\n",
      "b     1     6\n",
      "c     0     5\n",
      "d     2     2\n",
      "e     0     8\n",
      "a    5\n",
      "b    1\n",
      "c    0\n",
      "d    2\n",
      "e    0\n",
      "Name: col1, dtype: int64\n",
      "a    5\n",
      "b    1\n",
      "c    0\n",
      "Name: col1, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(np.random.randint(0,10,(5,2)),columns=['col1','col2'],index=['a','b','c','d','e']) # from array\n",
    "print(data)\n",
    "print(data['col1'])  # we can select columns (but not rows)\n",
    "print(data.loc['a':'c','col1']) # to access sub arrays, or rows, we must use .loc (location)\n",
    "print(data.iloc[4,0]) # or .iloc (index location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can modify the data in a straight forward manner, but not the indexes.  It is also easy to add more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1  col2\n",
      "a     6     8\n",
      "b     5     3\n",
      "c     6     9\n",
      "d     0     9\n",
      "e     7     8\n",
      "   col1  col2\n",
      "a     0     8\n",
      "b     5     3\n",
      "c     6     9\n",
      "d     0     9\n",
      "e     7     8\n",
      "   col1  col2  col3\n",
      "a     0     8     8\n",
      "b     5     3     8\n",
      "c     6     9    15\n",
      "d     0     9     9\n",
      "e     7     8    15\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(np.random.randint(0,10,(5,2)),columns=['col1','col2'],index=['a','b','c','d','e']) # from array\n",
    "print(data)\n",
    "data.loc['a']['col1']=0\n",
    "print(data)\n",
    "data['col3'] = data['col1']+data['col2']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also do hierarchial indexing for both rows and columns, which makes it effectively higher dimensional, you can switch between `Series` and `DataFrame` with `stack` and `unstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      col1      col2     \n",
      "      sub1 sub2 sub1 sub2\n",
      "a pt1    4    2    1    2\n",
      "  pt2    9    1    4    4\n",
      "b pt1    9    1    5    5\n",
      "  pt2    0    1    8    5\n",
      "c pt1    0    6    9    3\n",
      "  pt2    0    4    5    5\n",
      "d pt1    6    4    7    7\n",
      "  pt2    3    1    2    8\n",
      "            col1  col2\n",
      "a pt1 sub1     4     1\n",
      "      sub2     2     2\n",
      "  pt2 sub1     9     4\n",
      "      sub2     1     4\n",
      "b pt1 sub1     9     5\n",
      "      sub2     1     5\n",
      "  pt2 sub1     0     8\n",
      "      sub2     1     5\n",
      "c pt1 sub1     0     9\n",
      "      sub2     6     3\n",
      "  pt2 sub1     0     5\n",
      "      sub2     4     5\n",
      "d pt1 sub1     6     7\n",
      "      sub2     4     7\n",
      "  pt2 sub1     3     2\n",
      "      sub2     1     8\n",
      "a  pt1  sub1  col1    4\n",
      "              col2    1\n",
      "        sub2  col1    2\n",
      "              col2    2\n",
      "   pt2  sub1  col1    9\n",
      "              col2    4\n",
      "        sub2  col1    1\n",
      "              col2    4\n",
      "b  pt1  sub1  col1    9\n",
      "              col2    5\n",
      "        sub2  col1    1\n",
      "              col2    5\n",
      "   pt2  sub1  col1    0\n",
      "              col2    8\n",
      "        sub2  col1    1\n",
      "              col2    5\n",
      "c  pt1  sub1  col1    0\n",
      "              col2    9\n",
      "        sub2  col1    6\n",
      "              col2    3\n",
      "   pt2  sub1  col1    0\n",
      "              col2    5\n",
      "        sub2  col1    4\n",
      "              col2    5\n",
      "d  pt1  sub1  col1    6\n",
      "              col2    7\n",
      "        sub2  col1    4\n",
      "              col2    7\n",
      "   pt2  sub1  col1    3\n",
      "              col2    2\n",
      "        sub2  col1    1\n",
      "              col2    8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(np.random.randint(0,10,(8,4)),columns=[['col1','col1','col2','col2'],['sub1','sub2','sub1','sub2']] \n",
    "                    ,index=[['a','a','b','b','c','c','d','d'],['pt1','pt2','pt1','pt2','pt1','pt2','pt1','pt2']])\n",
    "print(data)\n",
    "data2 = data.stack()\n",
    "print(data2)\n",
    "data3 = data2.stack()\n",
    "print(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a wealth of things you can do with pandas including some quite sophisticated analysis tools which are very heavily used in business enviroments.  The main use of pandas for me is that is has a number of commands which are useful for reading in data from other sources.  Here are some of the more useful:\n",
    "\n",
    "- `pd.read_csv()`\n",
    "- `pd.read_table()`\n",
    "- `pd.read_clipboard()`\n",
    "\n",
    "They have alot of options to specify what to use for delimiters etc..\n",
    "\n",
    "You can also do this with numpy using `genfromtxt`\n",
    "\n",
    "For very large files you should consider using the HDF5 format and the `h5py` package which allows efficent read/wring for large files and even parallel read/writes which can be useful for very large files.  I'll leave you to investigate further,  http://docs.h5py.org/en/stable/index.html, if you think this will be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MatPlotLib\n",
    "\n",
    "This I will spend a bit of time on as you will likely use it alot.  It is a package for creating publication quality 2D plots from your data.  It is based on MatLab so you if you have used that you may be familiar with the syntax.  The plus side is you can create great looking plots the downside is it could be much more intuative to use.\n",
    "\n",
    "### Plot options\n",
    "Let's start with the simplest possible example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# for interactive mode:\n",
    "# %matplotlib notebook\n",
    "# for static mode: \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,50)\n",
    "y = np.sin(x)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks pretty good but lets play with it a bit.   First lets add another line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,50)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "plt.plot(x,y1)\n",
    "plt.plot(x,y2) # to add another line just call plot again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not lets add some options for lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x) + 0.2\n",
    "y3 = np.sin(x) + 0.4\n",
    "y4 = np.sin(x) + 0.6\n",
    "y5 = np.sin(x) + 0.8\n",
    "y6 = np.sin(x) + 1\n",
    "plt.plot(x,y1,linestyle='-',linewidth=1,color='r',marker=('o'))\n",
    "plt.plot(x,y2,linestyle='--',linewidth=2,color='#BDB76B',marker=('^'))\n",
    "plt.plot(x,y3,linestyle='-.',linewidth=3,color=(139/255, 0, 139/255),marker=('s'))\n",
    "plt.plot(x,y4,linestyle=':',linewidth=4,color='lime',marker=('*'))\n",
    "plt.plot(x,y5,linestyle=' ',marker=('$H$'),color='steelblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's think about the rest of the stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x) + 0.2\n",
    "y3 = np.sin(x) + 0.4\n",
    "y4 = np.sin(x) + 0.6\n",
    "y5 = np.sin(x) + 0.8\n",
    "y6 = np.sin(x) + 1\n",
    "\n",
    "#aspect ratio\n",
    "w, h = plt.figaspect(0.36)\n",
    "plt.figure('Sin plots',figsize=(w,h))\n",
    "\n",
    "plt.plot(x,y1,linestyle='-',linewidth=1,color='r',marker=('o'))\n",
    "plt.plot(x,y2,linestyle='--',linewidth=2,color='#00FA9A',marker=('^'))\n",
    "plt.plot(x,y3,linestyle='-.',linewidth=3,color=(139/255, 0, 139/255),marker=('s'))\n",
    "plt.plot(x,y4,linestyle=':',linewidth=4,color='lightcoral',marker=('*'))\n",
    "plt.plot(x,y5,linestyle=' ',marker=('$H$'),color='steelblue')\n",
    "\n",
    "# Tick location and limits\n",
    "plt.xticks((0,1,2,3,4,5))\n",
    "plt.xlim(0,5)\n",
    "plt.yticks((-1,0,1,2))\n",
    "plt.ylim(-1,2)\n",
    "\n",
    "# Make ticks point inwards and also appear top and right\n",
    "plt.tick_params(direction='in',top=True,right=True)\n",
    "\n",
    "# Add some labels\n",
    "plt.title('Plot of some stuff',fontfamily = 'cursive',fontsize = 'xx-large',fontstyle='italic',fontweight = 'light')\n",
    "plt.ylabel('This is the $y$ axis',fontfamily = 'fantasy',fontsize = 'xx-large',fontstyle='oblique',fontweight = 'heavy')\n",
    "plt.xlabel('This is the $x$ axis',fontfamily = 'serif',fontsize = 'xx-large',fontstyle='normal',fontweight = 'medium')\n",
    "\n",
    "# add a legend, annoyingly here you can't use most font commands but have to set it manually and import as 'prop'\n",
    "# you can also label the lines in the plot diective with: label='name here'\n",
    "import matplotlib.font_manager as font_manager\n",
    "font = font_manager.FontProperties(family='Comic Sans MS',weight='bold',style='normal', size=16)\n",
    "plt.legend(('A','B','C','D','E'),prop=font,loc='upper right', shadow=True)\n",
    "\n",
    "# removed extra white space\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib actually has two interfaces for plotting.  The above is the matlab version but you can also use the object oriented interface as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x) + 0.2\n",
    "y3 = np.sin(x) + 0.4\n",
    "y4 = np.sin(x) + 0.6\n",
    "y5 = np.sin(x) + 0.8\n",
    "y6 = np.sin(x) + 1\n",
    "\n",
    "#aspect ratio\n",
    "w, h = plt.figaspect(0.36)\n",
    "fig = plt.figure('Sin plots',figsize=(w,h))\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(x,y1,linestyle='-',linewidth=1,color='r',marker=('o'))\n",
    "ax.plot(x,y2,linestyle='--',linewidth=2,color='#00FA9A',marker=('^'))\n",
    "ax.plot(x,y3,linestyle='-.',linewidth=3,color=(139/255, 0, 139/255),marker=('s'))\n",
    "ax.plot(x,y4,linestyle=':',linewidth=4,color='lightcoral',marker=('*'))\n",
    "ax.plot(x,y5,linestyle=' ',marker=('$H$'),color='steelblue')\n",
    "\n",
    "# Tick location and limits\n",
    "ax.set(xticks=(0,1,2,3,4,5),xlim=(0,5),yticks=(-1,0,1,2),ylim=(-1,2))\n",
    "\n",
    "# Make ticks point inwards and also appear top and right\n",
    "ax.tick_params(direction='in',top=True,right=True)\n",
    "\n",
    "# Add some labels\n",
    "ax.set_title('Plot of some stuff',fontfamily = 'cursive',fontsize = 'xx-large',fontstyle='italic',fontweight = 'light')\n",
    "ax.set_ylabel('This is the $y$ axis',fontfamily = 'fantasy',fontsize = 'xx-large',fontstyle='oblique',fontweight = 'heavy')\n",
    "ax.set_xlabel('This is the $x$ axis',fontfamily = 'serif',fontsize = 'xx-large',fontstyle='normal',fontweight = 'medium')\n",
    "\n",
    "# add a legend, annoyingly here you can't use most font commands but have to set it manually and import as 'prop'\n",
    "import matplotlib.font_manager as font_manager\n",
    "font = font_manager.FontProperties(family='Comic Sans MS',weight='bold',style='normal', size=16)\n",
    "ax.legend(('A','B','C','D','E'),prop=font,loc='upper right', shadow=True)\n",
    "\n",
    "# removed extra white space\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't matter too much which you use but the object orentated interface can be easier for figures with multiple plots on it.  Let's look at doing multiple plots in one figure now.  Here is the simple case for a grid of plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x + 0.2)\n",
    "y3 = np.sin(x + 0.4)\n",
    "y4 = np.sin(x + 0.6)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1)\n",
    "\n",
    "# now we decide the actual figure size in inches\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "# create subplots 231 means make a 2x3 grid and this is the first plot\n",
    "plt.subplot(231)\n",
    "plt.plot(x,y1,color='r')\n",
    "plt.subplot(232)\n",
    "plt.plot(x,y2,color='g')\n",
    "plt.subplot(233)\n",
    "plt.plot(x,y3,color='b')\n",
    "plt.subplot(234)\n",
    "plt.plot(x,y4,color='y')\n",
    "plt.subplot(235)\n",
    "plt.plot(x,y5,color='c')\n",
    "plt.subplot(236)\n",
    "plt.plot(x,y6,color='m')\n",
    "# removed extra white space\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In object oriented mode this is a little easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x + 0.2)\n",
    "y3 = np.sin(x + 0.4)\n",
    "y4 = np.sin(x + 0.6)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1)\n",
    "\n",
    "# now we decide the actual figure and share x and y axes\n",
    "fig, ax = plt.subplots(2,3,figsize=(12,6), sharex=True,sharey=True)\n",
    "\n",
    "# Now each plot has a location defined by the numpy array ax\n",
    "ax[0,0].plot(x,y1,color='r')\n",
    "ax[0,1].plot(x,y2,color='g')\n",
    "ax[0,2].plot(x,y3,color='b')\n",
    "ax[1,0].plot(x,y4,color='y')\n",
    "ax[1,1].plot(x,y5,color='c')\n",
    "ax[1,2].plot(x,y6,color='m')\n",
    "# removed extra white space\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make multiple plots of different sizes by creating 2 sets of subplots which are multiples of each other using the same method (with matlab style interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x + 0.2)\n",
    "y3 = np.sin(x + 0.4)\n",
    "y4 = np.sin(x + 0.6)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1.0)\n",
    "y7 = np.sin(x + 1.2)\n",
    "\n",
    "# now we decide the actual figure size in inches\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "# create subplots now we have created a 2x2 grid and a 4x4 grid and fitted them together\n",
    "plt.subplot(221)\n",
    "plt.plot(x,y1,color='r')\n",
    "plt.subplot(223)\n",
    "plt.plot(x,y2,color='g')\n",
    "plt.subplot(224)\n",
    "plt.plot(x,y7,color='k')\n",
    "\n",
    "plt.subplot(443)\n",
    "plt.plot(x,y3,color='b')\n",
    "plt.subplot(444)\n",
    "plt.plot(x,y4,color='y')\n",
    "plt.subplot(447)\n",
    "plt.plot(x,y5,color='c')\n",
    "plt.subplot(448)\n",
    "plt.plot(x,y6,color='m')\n",
    "\n",
    "# removed extra white space\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But here it is better to use `gridspec`, which also gives better layout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,20)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x + 0.2)\n",
    "y3 = np.sin(x + 0.4)\n",
    "y4 = np.sin(x + 0.6)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1.0)\n",
    "y7 = np.sin(x + 1.2)\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "# import gridspec and create a 4x4 grid\n",
    "# we can also specifc the ratios of the sections of the grid relative to each other\n",
    "import matplotlib.gridspec as gs\n",
    "grid = gs.GridSpec(4, 4,width_ratios=[1,1,1,2],height_ratios=[1,1,1,1])\n",
    "\n",
    "# Create axis objects for each plot\n",
    "ax1 = plt.subplot(grid[0:2,0:2])\n",
    "ax2 = plt.subplot(grid[2:4,0:2])\n",
    "ax3 = plt.subplot(grid[2:4,2:4])\n",
    "ax4 = plt.subplot(grid[0,2])\n",
    "ax5 = plt.subplot(grid[0,3])\n",
    "ax6 = plt.subplot(grid[1,2])\n",
    "ax7 = plt.subplot(grid[1,3])\n",
    "\n",
    "# create subplots now we have created a 2x2 grid and a 4x4 grid and fitted them together\n",
    "ax1.plot(x,y1,color='r')\n",
    "ax2.plot(x,y2,color='g')\n",
    "ax3.plot(x,y7,color='k')\n",
    "\n",
    "ax4.plot(x,y3,color='b')\n",
    "ax5.plot(x,y4,color='y')\n",
    "ax6.plot(x,y5,color='c')\n",
    "ax7.plot(x,y6,color='m')\n",
    "\n",
    "# removed extra white space\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go back to the previous example of 6 plots in a regular grid we can do it with `gridspec` which gives us more control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x + 0.2)\n",
    "y3 = np.sin(x + 0.4)\n",
    "y4 = np.sin(x + 0.6)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1.0)\n",
    "y7 = np.sin(x + 1.2)\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "# import gridspec and create a 4x4 grid\n",
    "# This time lets join them up into one\n",
    "import matplotlib.gridspec as gs\n",
    "grid = gs.GridSpec(2,3,wspace=0,hspace=0)\n",
    "\n",
    "# Create axis objects for each plot\n",
    "ax1 = plt.subplot(grid[0,0])\n",
    "ax2 = plt.subplot(grid[0,1])\n",
    "ax3 = plt.subplot(grid[0,2])\n",
    "ax4 = plt.subplot(grid[1,0])\n",
    "ax5 = plt.subplot(grid[1,1])\n",
    "ax6 = plt.subplot(grid[1,2])\n",
    "\n",
    "# create subplots for all 6\n",
    "ax1.plot(x,y1,color='r')\n",
    "ax2.plot(x,y2,color='g')\n",
    "ax3.plot(x,y7,color='b')\n",
    "ax4.plot(x,y3,color='y')\n",
    "ax5.plot(x,y4,color='c')\n",
    "ax6.plot(x,y5,color='m')\n",
    "\n",
    "# Turn the ticks inward\n",
    "ax1.tick_params(direction='in',top=True,right=True)\n",
    "ax2.tick_params(direction='in',top=True,right=True)\n",
    "ax3.tick_params(direction='in',top=True,right=True)\n",
    "ax4.tick_params(direction='in',top=True,right=True)\n",
    "ax5.tick_params(direction='in',top=True,right=True)\n",
    "ax6.tick_params(direction='in',top=True,right=True)\n",
    "\n",
    "# set the limits to be the same so they line up perfectly\n",
    "ax1.set(xlim=(0,5),ylim=(-1.05,1.05))\n",
    "ax2.set(xlim=(0,5),ylim=(-1.05,1.05))\n",
    "ax3.set(xlim=(0,5),ylim=(-1.05,1.05))\n",
    "ax4.set(xlim=(0,5),ylim=(-1.05,1.05))\n",
    "ax5.set(xlim=(0,5),ylim=(-1.05,1.05))\n",
    "ax6.set(xlim=(0,5),ylim=(-1.05,1.05))\n",
    "\n",
    "# Add grids\n",
    "ax1.grid(True)\n",
    "ax2.grid(True)\n",
    "ax3.grid(True)\n",
    "ax4.grid(True)\n",
    "ax5.grid(True)\n",
    "ax6.grid(True)\n",
    "\n",
    "# remove tick labels for interior axes\n",
    "ax1.xaxis.set(ticklabels=[])\n",
    "ax2.xaxis.set(ticklabels=[])\n",
    "ax3.xaxis.set(ticklabels=[])\n",
    "\n",
    "ax2.yaxis.set(ticklabels=[])\n",
    "ax3.yaxis.set(ticklabels=[])\n",
    "ax5.yaxis.set(ticklabels=[])\n",
    "ax6.yaxis.set(ticklabels=[])\n",
    "\n",
    "# removed extra white space (you should alway do this as it always makes the plot better)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of plots\n",
    "\n",
    "Thats the basic type of plot but there are many others, here is a selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,30)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "e1 = 0.1*np.random.randn(len(x),1)\n",
    "e2 = 0.2*np.random.randn(len(x),1)\n",
    "h1 = 100 + 20*np.random.randn(10000)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1.0)\n",
    "y7 = np.sin(x + 1.2)\n",
    "\n",
    "# create figure\n",
    "fig = plt.figure(figsize=(15,6))\n",
    "# import gridspec and create a 4x4 grid\n",
    "# This time lets join them up into one\n",
    "import matplotlib.gridspec as gs\n",
    "grid = gs.GridSpec(2,4)\n",
    "\n",
    "# Create axis objects for each plot\n",
    "ax1 = plt.subplot(grid[0,0])\n",
    "ax2 = plt.subplot(grid[0,1])\n",
    "ax3 = plt.subplot(grid[0,2])\n",
    "ax4 = plt.subplot(grid[0,3])\n",
    "ax5 = plt.subplot(grid[1,0])\n",
    "ax6 = plt.subplot(grid[1,1])\n",
    "ax7 = plt.subplot(grid[1,2], projection='polar')\n",
    "ax8 = plt.subplot(grid[1,3])\n",
    "\n",
    "ax1.fill_between(x,y1,y2)\n",
    "ax2.errorbar(x,y1,fmt='.k',xerr=e1,yerr=e2,linestyle=' ')\n",
    "ax3.loglog(x,y1)\n",
    "ax4.hist(h1,50)\n",
    "ax5.scatter(e1,e2,c=e1)\n",
    "ax6.pie(np.abs(y1))\n",
    "ax7.plot(x,y1)\n",
    "ax8.plot(x,y1)\n",
    "\n",
    "ax8.text(1.3,0.6,'Max')\n",
    "\n",
    "# removed extra white space (you should alway do this as it always makes the plot better)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also change the style of the plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,5,100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.sin(x + 0.2)\n",
    "y3 = np.sin(x + 0.4)\n",
    "y4 = np.sin(x + 0.6)\n",
    "y5 = np.sin(x + 0.8)\n",
    "y6 = np.sin(x + 1.0)\n",
    "y7 = np.sin(x + 1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(('dark_background')):\n",
    "    plt.plot(x,y5,color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(('classic')):\n",
    "    plt.plot(x,y1,color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(('ggplot')):\n",
    "    plt.plot(x,y2,color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(('grayscale')):\n",
    "    plt.plot(x,y4,color='c')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(('seaborn')):\n",
    "    plt.plot(x,y7,color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with plt.style.context(('seaborn-white')):\n",
    "    plt.plot(x,y3,color='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last two are included from the `seaborn` package which sits of the the top of matplotlib and is good for stats plots (https://seaborn.pydata.org).\n",
    "\n",
    "### Examples\n",
    "\n",
    "3. Plot a Rainbow, ie:\n",
    "![](Plots/Rainbow.png)\n",
    "4. Generate a 2d multivariate data set with mean [1,2] and covariance [[1,2],[2,5]] then plot it like this:\n",
    "![](Plots/Multivar.png)\n",
    "\n",
    "\n",
    "\n",
    "### 3D plots\n",
    "\n",
    "There are also a limited number of 3D plots you can do with matplotlib (which was originally designed primarily for 2D plots). Here are the main options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "x = np.linspace(0,20,100)\n",
    "y = x*np.sin(x)\n",
    "z = x*np.cos(x)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot3D(x,y,z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,20,100)\n",
    "y = x*np.sin(x)\n",
    "z = x*np.cos(x)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.scatter3D(x,y,z,c=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,100)\n",
    "y = x\n",
    "X,Y=np.meshgrid(x,y)\n",
    "\n",
    "Z = (X-5)**2 + (Y-5)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.contour3D(X,Y,Z,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u, v = np.mgrid[0:2*np.pi:100j, 0:np.pi:50j]\n",
    "x = np.cos(u)*np.sin(v)\n",
    "y = np.sin(u)*np.sin(v)\n",
    "z = np.cos(v)\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_wireframe(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,10,100)\n",
    "y = x\n",
    "X,Y=np.meshgrid(x,y)\n",
    "\n",
    "Z = (X-5)**2 + (Y-5)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(X,Y,Z,rstride=1,cstride=1,cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,20,100)\n",
    "y = np.linspace(0,2*np.pi,100)\n",
    "\n",
    "r,t=np.meshgrid(x,y)\n",
    "\n",
    "X = r * np.sin(t)\n",
    "Y = r * np.cos(t)\n",
    "\n",
    "Z = (X-5)**2 + (Y-5)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_surface(X,Y,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 2*np.random.random(1000)-1e0\n",
    "y = 2*np.random.random(1000)-1e0\n",
    "\n",
    "z = x**2 + y**3\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "ax.plot_trisurf(x,y,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are OK for basic stuff but are a bit limited, say coloring them based on anything but z value.  To get more advanced there is `mayavi` with the warning that is is a real pain to install due to its dependencies.  The 'full noise' tool is `vtk` again a massive pain to install (you'll need to set up a new enviroment with python 2.7 then switch to that to use them).  Paraview also but not python.  https://www.paraview.org/Wiki/The_ParaView_Tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
